#!/bin/bash
# ğŸš€ BlackRoad AI - Deploy Full AI Cluster
# Deploys Qwen, Ollama, and API Gateway to all Pis

set -e

echo "ğŸŒŒ BlackRoad AI - Full Cluster Deployment"
echo "=========================================="

# Configuration
MODELS_DIR=~/blackroad-ai-models
PI_NODES=("lucidia:192.168.4.38" "aria:192.168.4.64" "alice:192.168.4.49" "octavia:192.168.4.74")
DEPLOY_TIMESTAMP=$(date +%s)

# Log start to memory
~/memory-system.sh log started "ai-cluster-deploy-$DEPLOY_TIMESTAMP" \
    "Starting full AI cluster deployment: Qwen + Ollama to ${#PI_NODES[@]} Pis + API Gateway" \
    "ai-deployment,cluster,major"

echo ""
echo "ğŸ“‹ Deployment Plan:"
echo "  â€¢ Qwen2.5 (Apache 2.0) - Port 8000"
echo "  â€¢ Ollama Multi-Model - Port 8001"
echo "  â€¢ API Gateway - Port 7000"
echo "  â€¢ Target Nodes: ${#PI_NODES[@]} Pis"
echo ""

# Function to deploy to a Pi
deploy_to_pi() {
    local host_info=$1
    local name="${host_info%%:*}"
    local ip="${host_info##*:}"

    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "ğŸ¯ Deploying to $name ($ip)"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

    # Create deployment directory
    echo "ğŸ“ Creating deployment directory..."
    ssh pi@$ip "mkdir -p ~/blackroad-ai/{qwen,ollama,gateway}"

    # Deploy Qwen
    echo "ğŸ¤– Deploying Qwen2.5..."
    cd $MODELS_DIR/qwen
    docker build -t blackroad-ai-qwen:latest . > /dev/null 2>&1
    docker save blackroad-ai-qwen:latest | gzip | \
        ssh pi@$ip "gunzip | docker load"
    scp docker-compose.yml pi@$ip:~/blackroad-ai/qwen/

    # Deploy Ollama
    echo "ğŸ”„ Deploying Ollama..."
    cd $MODELS_DIR/ollama
    docker build -t blackroad-ai-ollama:latest . > /dev/null 2>&1
    docker save blackroad-ai-ollama:latest | gzip | \
        ssh pi@$ip "gunzip | docker load"
    scp docker-compose.yml pi@$ip:~/blackroad-ai/ollama/

    # Create network
    echo "ğŸŒ Creating Docker network..."
    ssh pi@$ip "docker network create blackroad-ai-network 2>/dev/null || true"

    # Start services
    echo "ğŸ¬ Starting services..."
    ssh pi@$ip "cd ~/blackroad-ai/qwen && docker-compose up -d"
    ssh pi@$ip "cd ~/blackroad-ai/ollama && docker-compose up -d"

    # Wait and health check
    echo "ğŸ¥ Waiting for services to start (60s)..."
    sleep 60

    echo "ğŸ¥ Health checks:"
    ssh pi@$ip "curl -f http://localhost:8000/health 2>/dev/null && echo '  âœ… Qwen online' || echo '  âŒ Qwen failed'"
    ssh pi@$ip "curl -f http://localhost:8001/health 2>/dev/null && echo '  âœ… Ollama online' || echo '  âŒ Ollama failed'"

    # Log to memory
    ~/memory-system.sh log completed "ai-deploy-$name" \
        "Deployed Qwen + Ollama to $name ($ip). Services running on ports 8000, 8001." \
        "ai-deployment,$name"

    echo "âœ… $name deployment complete!"
    echo ""
}

# Deploy to all Pis
for node in "${PI_NODES[@]}"; do
    deploy_to_pi "$node" &
done

# Wait for all deployments
echo "â³ Waiting for parallel deployments..."
wait

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸŒ Deploying API Gateway (local)"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

cd $MODELS_DIR/api-gateway
docker network create blackroad-ai-network 2>/dev/null || true
docker-compose up -d

echo "â³ Waiting for gateway (30s)..."
sleep 30

# Test gateway
echo "ğŸ¥ Testing API Gateway..."
curl -f http://localhost:7000/health && echo "âœ… Gateway online!" || echo "âŒ Gateway failed"

# Log completion
~/memory-system.sh log milestone "ai-cluster-deployed" \
    "ğŸ‰ FULL AI CLUSTER DEPLOYED!

âœ… Deployed to ${#PI_NODES[@]} Pis:
$(for node in "${PI_NODES[@]}"; do echo "  â€¢ ${node%%:*}"; done)

ğŸ“¦ Services per Pi:
  â€¢ Qwen2.5 (port 8000)
  â€¢ Ollama with 4 models (port 8001)

ğŸŒ API Gateway (port 7000):
  â€¢ Load balancing
  â€¢ Auto-failover
  â€¢ [MEMORY] integration

Total model instances: $((${#PI_NODES[@]} * 2)) nodes
Total models available: 5+ (Qwen2.5, DeepSeek-R1, Llama3.2, Mistral, etc.)

ğŸ–¤ğŸ›£ï¸ BlackRoad AI infrastructure is LIVE!" \
    "ai-deployment,cluster,milestone,success"

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ¨ DEPLOYMENT COMPLETE âœ¨"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ğŸŒ API Gateway: http://localhost:7000"
echo "ğŸ“Š Health: http://localhost:7000/health"
echo "ğŸ“‹ Models: http://localhost:7000/models"
echo ""
echo "ğŸ’¬ Test it:"
echo '  curl -X POST http://localhost:7000/chat \'
echo '    -H "Content-Type: application/json" \'
echo '    -d '"'"'{"message": "Hello AI!", "model": "auto"}'"'"''
echo ""
echo "ğŸ–¤ğŸ›£ï¸ BlackRoad AI is online!"
